---
title: "Feed me back now:"
subtitle: "Tales of automated feedback <br> in R and Python"
author: "Mine Çetinkaya-Rundel & Tiffany Timbers"
date: "2020/05/20 (updated: `r Sys.Date()`) <br> TODO: INSERT LINK TO SLIDES"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#0F4C81",   # pantone classic blue
  secondary_color = "#7A8387", # pantone monument
  header_font_google = google_font("Arvo"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Source Code Pro")
)
```

class: center, middle

# Automated feedback in learnr

(Mine Çetinkaya-Rundel)

---

class: center, middle

# Automated feedback via GitHub Actions

(Mine Çetinkaya-Rundel)

---

class: center, middle

# Automated feedback in Jupyter
(Tiffany Timbers)

---

## What is Jupyter?

---

## Tests as automated feedback

---

## Autograding via nbgrader

---

class: center, middle

# Demo!

---

class: center, middle

# Closing thoughts

---

## Best practices for automated feedback

- Measure twice, cut once (verify the correctness of your tests).

- Use rounding & type coercion to write robust tests.

- Use hashing to hide solutions for visible tests.

- Test your tests on the students compute environment.

- Abstract your tests to a script that is sourced/imported into the students literate code document.

- Don't give automated feedback on everything.

---

## Resources

- [nbgrader docs](https://nbgrader.readthedocs.io/en/stable/) (autograding in Jupyter notebooks)
